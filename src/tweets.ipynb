{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68b23343-2ba0-44a3-8ff9-82ec0c2a2fdd",
   "metadata": {},
   "source": [
    "# Extraction historical tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908cfebb-a2d5-4f9b-91bc-60b1a7ceb9b2",
   "metadata": {},
   "source": [
    "## Importing all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a37b0fb-a130-4dea-89e4-6cc879162256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /opt/conda/lib/python3.7/site-packages (4.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (3.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "239923ef-bfaa-4971-9b8c-0568dd246acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760fb923-23f0-46fe-a470-e095c809182f",
   "metadata": {},
   "source": [
    "For our project we will be using tweets from the last 2 years using the Twitter API. To access this data is necessary to have a developer account on Twitter and the [Academic Research credentials](https://developer.twitter.com/en/products/twitter-api/academic-research). The keys are stored in the `twitter_keys.yaml` file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ab12a42-b2f3-4517-bbd3-9a44072ebfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = open(\"twitter_keys.yaml\")\n",
    "config = yaml.safe_load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9afe72a9-1010-4d93-a176-829843d87e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = config['API Key']\n",
    "api_key_secret = config['API Key Secret']\n",
    "access_token = config['Access token']\n",
    "access_token_secret = config['Access token secret']\n",
    "bearer_token = config['Bearer token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394db046-ac1f-4ce3-b3fd-7661244b1c89",
   "metadata": {},
   "source": [
    "To get the data, we will use [tweepy.Client](https://docs.tweepy.org/en/stable/client.html) and the [search_all_tweets] method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5528ea27-ebd9-480c-a581-2a1b4345f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "355daf80-d151-4025-b8c8-9bd171126ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start date to query tweets \n",
    "start_date = datetime.date(2021,10,31)\n",
    "end_date = datetime.date(2022,3,13)\n",
    "\n",
    "# Function to generate dates\n",
    "def gen_dates(start_date, end_date):\n",
    "    new_start = start_date\n",
    "    while new_start != end_date:\n",
    "        new_start += one_day\n",
    "        yield new_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb3663f6-68e3-4fa6-a80c-808eb08d8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=[]\n",
    "\n",
    "# Date in the right format to query\n",
    "for d in gen_dates(start_date, end_date):\n",
    "    new_date = str(d) + 'T00:00:00Z'\n",
    "    dates.append(new_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9c006-1b6f-4051-9345-ee8633af64bc",
   "metadata": {},
   "source": [
    "We will look for tweets that contain the word *Bitcoin* with these characteristics:\n",
    "- Not a retweet\n",
    "- English\n",
    "- Verified Accounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18cee536-1b7a-4ea2-89ea-a363e93755c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 412 seconds.\n"
     ]
    }
   ],
   "source": [
    "final_tweets = []\n",
    "for i in range (len(dates)-1):\n",
    "    hoax_tweets = []\n",
    "    for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = 'Bitcoin -is:retweet lang:en is:verified',\n",
    "                                 user_fields = ['username', 'public_metrics', 'description', 'location'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = dates[i],\n",
    "                                 end_time = dates[i+1],\n",
    "                              max_results=200):\n",
    "                              time.sleep(1)\n",
    "                              hoax_tweets.append(response)\n",
    "                              final_tweets.append(response)\n",
    "                              if len(hoax_tweets) == 20:\n",
    "                                  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "baef1c09-c8e4-4371-a987-2ec7ab4785b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba63f89-5b3b-4ced-a782-45016e4c689e",
   "metadata": {},
   "source": [
    "Once we have the raw data from the Twitter API, we will keep only the information we care. \n",
    "- Username\n",
    "- Followers\n",
    "- Tweets\n",
    "- Description \n",
    "- Location\n",
    "- ID (tweet)\n",
    "- ID (Author)\n",
    "- Created at \n",
    "- Tweet\n",
    "- Likes\n",
    "- Retweets\n",
    "- Quotes\n",
    "\n",
    "We transform the `created_at` field into a string to be able to save it later like a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "008797fb-2b4a-4482-850b-c961a631f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "user_dict = {}\n",
    "# Loop through each response object\n",
    "for response in final_tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'username': user.username, \n",
    "                              'followers': user.public_metrics['followers_count'],\n",
    "                              'tweets': user.public_metrics['tweet_count'],\n",
    "                              'description': user.description,\n",
    "                              'location': user.location\n",
    "                             }\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "        result.append({'id': str(tweet.id), \n",
    "                       'author_id': str(tweet.author_id),\n",
    "                       'username': author_info['username'],\n",
    "                       'author_followers': author_info['followers'],\n",
    "                       'author_tweets': author_info['tweets'],\n",
    "                       'author_description': author_info['description'],\n",
    "                       'author_location': author_info['location'],\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': str(tweet.created_at),\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count']\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db14ac08-559f-4848-abc8-ef77d6a4b849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97281"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72726f70-f498-483e-8ade-728f6ab09be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1469462654808961024',\n",
       " 'author_id': '17899712',\n",
       " 'username': 'Kevin_Jackson',\n",
       " 'author_followers': 77459,\n",
       " 'author_tweets': 209109,\n",
       " 'author_description': 'USA Today & Wall Street Journal bestselling author, advisor, & technologist. https://t.co/JQmBpxpgul https://t.co/5cowsJ2iMPâ€¦',\n",
       " 'author_location': 'Virginia, USA',\n",
       " 'text': '@ILokeli, Earn Bitcoin while protecting yourself from text and voice scams with Gabriel Crypto. Use code TNS2021 after checkout to get 60 points you can exchange for crypto!\\nhttps://t.co/eWm1Th5GzQ\\nhttps://t.co/bWBkHhnBrJ',\n",
       " 'created_at': '2021-12-11 00:22:52+00:00',\n",
       " 'retweets': 0,\n",
       " 'replies': 0,\n",
       " 'likes': 0,\n",
       " 'quote_count': 0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[32983]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd8ff2-de27-4910-a091-f819960366cd",
   "metadata": {},
   "source": [
    "At last we load these date into our **tweets_crypto** bucket. We stored the data with the following structure `year/month/tweet_id.json` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ecb9d8-4554-4997-beee-11b3ffcee31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = config['bucket']\n",
    "client = storage.Client()\n",
    "gcs_bucket = client.get_bucket(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39a1d1e-0ee0-41fb-ac59-af9d38890713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets_crypto\n"
     ]
    }
   ],
   "source": [
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd146cb-ea53-41ec-ba0b-01286ecc6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result:\n",
    "    path = f\"tweets/{row['created_at'][:4]}/{row['created_at'][5:7]}/tweet_{row['id']}.json\"\n",
    "    blob = gcs_bucket.blob(path)\n",
    "    with blob.open(mode = 'w') as file:\n",
    "        json.dump(row, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3315fa04-33d4-4a6c-a6a8-f862e88f28c4",
   "metadata": {},
   "source": [
    "As the data takes a while to load into the bucket, we stored the data form november 2021 up today in the `nov_march_2022.json` file. These will uploaded also into the bucket, the same way as the previous data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79e46c9d-afcf-47d8-ac5f-b1d39ef6843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_result = json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b03f7888-7e46-48ae-8cca-ab7aab4b20c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('nov_march_2022.json', 'w') as outfile:\n",
    "    json.dump(json_result, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c7d0f2-bc5c-4683-a558-322db0ee76bf",
   "metadata": {},
   "source": [
    "## Extraction of tweets last 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c0ccd2-fe22-4872-a0ff-8295b73f5819",
   "metadata": {},
   "source": [
    "Here is a way to extract data from the last 7 days, and this will be use to feed our model with new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b9edbf-d3f8-4f94-a085-5736d5a9dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2666a5f6-7619-4623-9552-4e5707d931bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = '#bitcoin'\n",
    "limit = 10\n",
    "tweets = tweepy.Cursor(api.search_tweets, lang = 'en', q = keywords, count = 100, tweet_mode = 'extended').items(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7adf455c-b07a-4217-9162-9b02a82cc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['User', 'Tweet', 'Date', 'Likes', 'Location', 'Followers']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.user.screen_name, tweet.full_text, tweet.created_at, tweet.favorite_count, tweet.user.location, tweet.user.followers_count])\n",
    "\n",
    "#df = pd.DataFrame(data, colum1s=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17765a95-4832-40ac-9516-cad10906d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "keywords = '#bitcoin'\n",
    "limit = 10\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search_tweets, lang = 'en', q = keywords, count = 100, tweet_mode = 'extended').items(limit):\n",
    "    data.append(tweet._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70dc2eca-09d0-4a5b-ae08-6dffadd32009",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=[]\n",
    "for i in data:\n",
    "    if i[\"lang\"] == \"en\":\n",
    "        test = {\n",
    "            \"id\": i[\"id\"],\n",
    "            \"lang\": i[\"lang\"],\n",
    "            \"created_at\": i[\"created_at\"],\n",
    "            \"text\": i[\"full_text\"],\n",
    "            \"retweet_count\": i[\"retweet_count\"],\n",
    "            \"raw_data\": i\n",
    "        }\n",
    "    data1.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdbadb7-ff4c-4ef9-b65d-e936f3b6b944",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e18e65-1cdf-46e8-8241-1316c44ee2bf",
   "metadata": {},
   "source": [
    "[Twitter V2 Full Archive Search]()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
